import os
import json
from multiprocessing import Pool, cpu_count, set_start_method
from pathlib import Path
from tqdm import tqdm
from prompt import *
import traceback
import time
import numpy as np
import os
import json

# ç›®æ ‡ JSON æ–‡ä»¶åï¼ˆæ£€æµ‹æ–‡ä»¶ï¼‰
TARGET_FILENAME = "detections_with_bbox_label_qwen_spital_caption_mask_pcd.json"

def load_all_whether_have_platform(root_path):
    """
    ä» root_path ä¸­é€’å½’è¯»å–æ‰€æœ‰ JSON æ–‡ä»¶ï¼Œåˆå¹¶æ‰€æœ‰æ•°ç»„é¡¹ï¼Œ
    å¹¶ç­›é€‰å‡º have_platform ä¸º True çš„ frame_folder_pathã€‚

    è¿”å›ï¼š
        List[str] æ‰€æœ‰ç¬¦åˆæ¡ä»¶çš„è·¯å¾„
    """
    all_items = []

    # éå†æ‰€æœ‰ json æ–‡ä»¶
    for dirpath, _, filenames in os.walk(root_path):
        for filename in filenames:
            if filename.endswith(".json"):
                json_path = os.path.join(dirpath, filename)
                try:
                    with open(json_path, "r") as f:
                        data = json.load(f)
                        if isinstance(data, list):
                            all_items.extend(data)
                        else:
                            print(f"âš ï¸ éæ•°ç»„ç»“æ„è·³è¿‡: {json_path}")
                except Exception as e:
                    print(f"âŒ è¯»å–å¤±è´¥: {json_path}\n{e}")

    return all_items

def check_and_clean_template_qa(frame_dir: dict, filename) -> str | None:
    """
    æ£€æŸ¥å¹¶å°è¯•åŠ è½½ frame_dir/template_qa.jsonã€‚
    å¦‚æœæŸååˆ™åˆ é™¤ï¼Œè¿”å›è¢«åˆ é™¤çš„è·¯å¾„ï¼›å¦åˆ™è¿”å› Noneã€‚
    """
    json_path = Path(frame_dir["frame_folder_path"]) / filename
    if not json_path.exists():
        return None

    try:
        with open(json_path, "r") as f:
            json.load(f)
    except Exception as e:
        print(f"âš ï¸ Invalid JSON: {json_path} â€” {e}. Deleting...")
        try:
            json_path.unlink()
            return str(json_path)
        except Exception as delete_error:
            print(f"âŒ Failed to delete {json_path}: {delete_error}")
    return None

def clean_all_template_qa(frame_dirs: list[dict], template_name):
    """
    æ‰¹é‡æ£€æŸ¥å¹¶æ¸…ç†æ‰€æœ‰ template_qa.json æ–‡ä»¶ã€‚
    """
    print(f"ğŸ§¹ Checking {len(frame_dirs)} folders...")
    for frame_dir in tqdm(frame_dirs, desc="Checking folders"):
        if check_and_clean_template_qa(frame_dir, template_name) is not None:
            print(f"âœ… Cleaned {frame_dir}/{template_name}")
    print("âœ… Done.")

def find_unprocessed_frame_dirs(frame_dirs: list[dict], filename) -> list[str]:
    """
    æ‰¾å‡ºè¿˜æ²¡æœ‰ç”Ÿæˆ template_qa.json çš„å¸§ç›®å½•
    """
    unprocessed = []
    for frame_dir in tqdm(frame_dirs, desc="ğŸ” Checking unprocessed frames"):
        template_path = Path(frame_dir["frame_folder_path"]) / filename
        if not template_path.exists():
            unprocessed.append(frame_dir)
    return unprocessed

def template_qa_generation(frame_dir, template_name):
    """
    ç”Ÿæˆ template_qa.json å¹¶ä¿å­˜åˆ° frame_dir ä¸­
    """
    # åœ¨æ¯ä¸ªå­è¿›ç¨‹ä¸­é‡æ–°åˆ›å»º VisualPromptGenerator
    prompt_generator = PromptGenerator()
    data_root = frame_dir["frame_folder_path"]
    data_path = Path(data_root) / "wide" / TARGET_FILENAME
    with open(data_path, 'r') as f:
        data = json.load(f)
    if not frame_dir["have_platform"]:
        result = {
            "image_path": data["image_path"],
            "image_resize_path": data["image_resized_path"],
            "gt_depth_path": data["gt_depth_path"],
            "wide_depth_path": data["wide_depth_path"],
            "image_caption": data["image_caption"],
            "qa_pairs": []
        }
        with open(f"{data_root}/{template_name}", 'w') as f:
            json.dump(result, f, indent=4)

        return
    
    detections = data["objects"]
    gt_depth_path = data["gt_depth_path"]
    wide_depth_path = data["wide_depth_path"]
    instances_path = os.path.join(data_root, "wide", "instances.json")
    T_gravity_path = os.path.join(data_root, "wide", "T_gravity.json")
    K_path = os.path.join(data_root, "wide", "depth", "K.json")

    qa_pairs = prompt_generator.evaluate_predicates_on_pairs(detections, instances_path, gt_depth_path, wide_depth_path, T_gravity_path, K_path)
    result = {
        "image_path": data["image_path"],
        "image_resize_path": data["image_resized_path"],
        "gt_depth_path": data["gt_depth_path"],
        "wide_depth_path": data["wide_depth_path"],
        "image_caption": data["image_caption"],
        "qa_pairs": [{
            "question": qa[0][0],
            "answer": qa[0][1],
            "object_A_index": qa[1],
            "object_B_index": qa[2],
            "object_C_index": qa[3],
            "qa_function": qa[4],
            "qa_type": qa[5],
        } for qa in qa_pairs]
    }
    with open(f"{data_root}/{template_name}", 'w') as f:
        json.dump(result, f, indent=4)

    return

def process_frame_dir(args):
    """
    åŒ…è£… template_qa_generation è°ƒç”¨ï¼Œå¹¶è¿”å›å¤„ç†æƒ…å†µã€‚
    """
    frame_dir, template_name = args
    try:
        template_qa_generation(frame_dir, template_name)
        return frame_dir  # æˆåŠŸå¤„ç†åè¿”å›å¤„ç†çš„å¸§ç›®å½•
    except Exception as e:
        print(f"Error processing {frame_dir}: {e}")
        traceback.print_exc()
        return None

def process_all_unprocessed_dirs(unprocessed_dirs: list[dict], template_name) -> list[str]:
    tasks = [(frame_dir, template_name) for frame_dir in unprocessed_dirs]
    processed_dirs = []
    pool = Pool(cpu_count())
    try:
        for result in tqdm(
            pool.imap_unordered(process_frame_dir, tasks, chunksize=1),
            total=len(tasks),
            desc="ğŸ”„ Processing unprocessed frames"
        ):
            if result is not None:
                processed_dirs.append(result)
    except KeyboardInterrupt:
        print("\nâš ï¸ KeyboardInterrupt detected, terminating pool and child processes...")
        pool.terminate()   # å¼ºåˆ¶ç»ˆæ­¢æ‰€æœ‰å­è¿›ç¨‹
        pool.join()
        raise             # å¯é€‰ï¼šé‡æ–°æŠ›å‡ºå¼‚å¸¸ï¼Œæˆ– return processed_dirs
    else:
        pool.close()
        pool.join()
    return processed_dirs

def check_frame_has_json(frame_path: Path) -> str | None:
    """
    æ£€æŸ¥æŸä¸ªå¸§ç›®å½•ä¸‹æ˜¯å¦å­˜åœ¨æŒ‡å®šçš„ wide/json æ–‡ä»¶ã€‚
    å¦‚æœå­˜åœ¨ï¼Œè¿”å› frame_pathï¼›å¦åˆ™è¿”å› Noneã€‚
    """
    json_path = frame_path / "wide" / TARGET_FILENAME
    if json_path.exists():
        return str(frame_path.resolve())
    return None

def find_all_frame_dirs(root_path: str, num_workers: int = None) -> list[str]:
    """
    å¤šè¿›ç¨‹æŸ¥æ‰¾æ‰€æœ‰åŒ…å«ç›®æ ‡ JSON çš„å¸§ç›®å½•ã€‚
    å‡è®¾ç»“æ„ä¸º root/video_id/frame_idã€‚
    """
    root = Path(root_path).resolve()
    if not root.exists():
        raise FileNotFoundError(f"Root path does not exist: {root_path}")

    # æŸ¥æ‰¾æ‰€æœ‰ä¸¤çº§ç›®å½•ï¼švideo_id/frame_id
    candidate_frame_dirs = [
        p.resolve() for p in tqdm(root.glob("*/*"), desc="Scanning folders")
        if p.is_dir()
    ]

    print(f"ğŸ” Found {len(candidate_frame_dirs)} candidate frame folders. Verifying...")
    
    valid_frame_dirs = []
    for candidate_frame_dir in tqdm(candidate_frame_dirs, desc="ğŸ” Checking frame folders"):
        if check_frame_has_json(candidate_frame_dir) is not None:
            valid_frame_dirs.append(str(candidate_frame_dir.resolve()))

    print(f"âœ… Found {len(valid_frame_dirs)} valid frame folders with expected JSON.")
    return valid_frame_dirs

def merge_frame_paths(platform_paths, frame_dirs):
    # 1. æŠŠå·²æœ‰çš„è·¯å¾„åšæˆä¸€ä¸ªå­—å…¸ï¼Œä¾¿äºæŸ¥æ‰¾
    platform_dict = {
        item['frame_folder_path']: item.get('have_platform', False)
        for item in platform_paths
    }
    # 2. æ„å»ºæ–°çš„å®Œæ•´åˆ—è¡¨
    result = []
    for frame_path in frame_dirs:
        have_platform = platform_dict.get(frame_path, False)
        result.append({
            "frame_folder_path": frame_path,
            "have_platform": have_platform
        })

    return result
# ç¤ºä¾‹ç”¨æ³•
if __name__ == "__main__":
    # ä¸ºé¿å… fork å¸¦æ¥çš„é—®é¢˜ï¼Œä½¿ç”¨ spawn å¯åŠ¨æ–¹å¼
    try:
        set_start_method('spawn', force=True)
    except RuntimeError:
        pass

    root_dir = "/home_sfs/zhouenshen/dataset/3D/cubifyanything/filter_step_20"
    template_name = "vacant_qa.json"
    whether_have_platform_path = "/home_sfs/zhouenshen/dataset/3D/cubifyanything/whether_have_platform"

    platform_paths = load_all_whether_have_platform(whether_have_platform_path)
    # âœ… ç¬¬ä¸€æ­¥ï¼šæŸ¥æ‰¾æ‰€æœ‰åˆæ³•çš„å¸§æ–‡ä»¶å¤¹ï¼ˆåŒ…å«ç›®æ ‡ JSONï¼‰
    frame_dirs = find_all_frame_dirs(root_dir)
    all_platform_paths = merge_frame_paths(platform_paths, frame_dirs)
    # ç¬¬äºŒæ­¥ï¼šæ£€æŸ¥å¹¶æ¸…ç†æŸåçš„ vacant_qa.json æ–‡ä»¶
    clean_all_template_qa(all_platform_paths, template_name)

    # ç¬¬ä¸‰æ­¥ï¼šæ‰¾å‡ºè¿˜æœªå¤„ç†çš„å¸§ç›®å½•ï¼ˆæ²¡æœ‰ vacant_qa.jsonï¼‰
    unprocessed_dirs = find_unprocessed_frame_dirs(all_platform_paths, template_name)

    # âœ… ç¬¬å››æ­¥ï¼šå¤šè¿›ç¨‹å¤„ç†æ‰€æœ‰æœªå¤„ç†å¸§
    processed_dirs = process_all_unprocessed_dirs(unprocessed_dirs, template_name)


