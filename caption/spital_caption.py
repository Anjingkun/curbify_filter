import random
from collections import defaultdict
from caption_template import TEMPLATES, ORDINALS
import os
import json
from tqdm import tqdm
from multiprocessing import Pool, cpu_count
from functools import partial

# è®¾ç½®æ ¹è·¯å¾„å’Œé˜ˆå€¼
ROOT_DIR = "/home_sfs/zhouenshen/dataset/3D/cubifyanything/filter_step_20"
JSON_FILENAME = "wide/detection_GroundingDino_bbox_RAM_label_qwen_caption_confidence25.json"
RATIO_THRESHOLD = 0.7

# ---------- å·¥å…·å‡½æ•° ----------
def get_bbox_extent_along_axis(corners, axis):
    values = [corner[axis] for corner in corners]
    return max(values) - min(values)

def get_min_z_from_corners(corners):
    return min(corner[2] for corner in corners)

def compute_lr_score(group, ratio_threshold):
    """
    è¯„ä¼°ä¸€ç»„ç‰©ä½“æ˜¯å¦é€‚åˆè¿›è¡Œå·¦å³æ’åºï¼ˆleft-to-rightï¼‰ï¼Œè¿”å›å¾—åˆ†ã€‚
    score = extent_x / total_width - (1 - ratio_threshold) / N
    """
    if len(group) < 2:
        return 0.0  # ä¸é€‚åˆæ’åº

    all_xs = [corner[0] for obj in group for corner in obj["corners"]]
    extent_x = max(all_xs) - min(all_xs)
    widths = [get_bbox_extent_along_axis(obj["corners"], 0) for obj in group]
    total_width = sum(widths)
    n = len(group)

    score = (extent_x / total_width) - ((1 - ratio_threshold) / n) if total_width > 0 else 0.0
    return score

def compute_tb_score(group, ratio_threshold):
    """
    è¯„ä¼°ä¸€ç»„ç‰©ä½“æ˜¯å¦é€‚åˆä¸Šä¸‹æ’åºï¼ˆtop-to-bottomï¼‰ï¼Œè¿”å›å¾—åˆ†ã€‚
    score = extent_y / total_height - (1 - ratio_threshold) / N
    """
    if len(group) < 2:
        return 0.0

    all_ys = [corner[1] for obj in group for corner in obj["corners"]]
    extent_y = max(all_ys) - min(all_ys)
    heights = [get_bbox_extent_along_axis(obj["corners"], 1) for obj in group]
    total_height = sum(heights)
    n = len(group)

    score = (extent_y / total_height) - ((1 - ratio_threshold) / n) if total_height > 0 else 0.0
    return score

def compute_fb_score(group, ratio_threshold):
    """
    è¯„ä¼°ä¸€ç»„ç‰©ä½“æ˜¯å¦é€‚åˆè¿›è¡Œå‰åæ’åºï¼ˆfront-to-backï¼‰ï¼Œè¿”å›å¾—åˆ†ã€‚
    score = extent_z / total_depth - (1 - ratio_threshold) / N
    """
    if len(group) < 2:
        return 0.0

    all_zs = [corner[2] for obj in group for corner in obj["corners"]]
    extent_z = max(all_zs) - min(all_zs)
    depths = [get_bbox_extent_along_axis(obj["corners"], 2) for obj in group]
    total_depth = sum(depths)
    n = len(group)

    score = (extent_z / total_depth) - ((1 - ratio_threshold) / n) if total_depth > 0 else 0.0
    return score

def sort_objects(group, direction):
    if direction == "left_to_right":
        return sorted(group, key=lambda o: o["position"][0])
    elif direction == "right_to_left":
        return sorted(group, key=lambda o: -o["position"][0])
    elif direction == "front_to_back":
        return sorted(group, key=lambda o: get_min_z_from_corners(o["corners"]))
    elif direction == "back_to_front":
        return sorted(group, key=lambda o: -get_min_z_from_corners(o["corners"]))
    elif direction == "top_to_bottom":
        return sorted(group, key=lambda o: o["position"][1])
    elif direction == "bottom_to_top":
        return sorted(group, key=lambda o: -o["position"][1])
    else:
        print("ğŸš¨ Invalid direction")
        return group

def generate_caption(obj, ordinal_index, direction):
    index = ordinal_index + 1
    # è·å–è‹±æ–‡åºæ•°è¯
    ordinal_word = ORDINALS.get(index)
    ordinal_number = f"{index}th"

    # å¦‚æœè‹±æ–‡åºæ•°è¯å­˜åœ¨ï¼Œåˆ™éšæœºç”¨ word æˆ–æ•°å­—å½¢å¼
    if ordinal_word:
        ordinal = random.choice([ordinal_word, ordinal_number])
    else:
        ordinal = ordinal_number

    template = random.choice(TEMPLATES[direction])
    return template.format(
        dense_caption=obj["dense_caption"],
        ordinal=ordinal,
        class_name=obj["class_name"]
    )

# ---------- ä¸»å‡½æ•° ----------
def process_objects(objects, ratio_threshold=0.7):
    grouped_objects = defaultdict(list)

    # æŒ‰ç±»åˆ†ç»„
    for obj in objects:
        obj["spatial_caption"] = []
        grouped_objects[obj["class_name"]].append(obj)

    # æ¯ç»„å¤„ç†
    for class_name, group in grouped_objects.items():
        if len(group) < 2:
            for obj in group:
                obj["spatial_caption"] = [obj["dense_caption"]]
            continue

        # è®¡ç®—å„æ–¹å‘çš„æ’åºé€‚é…å¾—åˆ†
        lr_score = compute_lr_score(group, ratio_threshold)
        fb_score = compute_fb_score(group, ratio_threshold)
        tb_score = compute_tb_score(group, ratio_threshold)

        directions_to_use = []

        if lr_score >= ratio_threshold:
            directions_to_use += ["left_to_right", "right_to_left"]
        if fb_score >= ratio_threshold:
            directions_to_use += ["front_to_back", "back_to_front"]
        if tb_score >= ratio_threshold:
            directions_to_use += ["top_to_bottom", "bottom_to_top"]

        if not directions_to_use:
            # å¦‚æœéƒ½ä¸æ»¡è¶³é˜ˆå€¼ï¼Œé€‰å¾—åˆ†æœ€é«˜çš„é‚£ä¸ªæ–¹å‘çš„ä¸¤ä¸ªæ–¹å‘ï¼ˆæ­£å‘ + åå‘ï¼‰
            scores = {
                "lr": lr_score,
                "fb": fb_score,
                "tb": tb_score
            }
            best = max(scores, key=scores.get)
            if best == "lr":
                directions_to_use += ["left_to_right", "right_to_left"]
            elif best == "fb":
                directions_to_use += ["front_to_back", "back_to_front"]
            else:
                directions_to_use += ["top_to_bottom", "bottom_to_top"]  
        # å¯¹æ¯ä¸ªæ–¹å‘è¿›è¡Œæ’åºå¹¶èµ‹ caption
        for direction in directions_to_use:
            sorted_group = sort_objects(group, direction)
            for idx, obj in enumerate(sorted_group):
                caption = generate_caption(obj, idx, direction)
                if "spatial_caption" not in obj:
                    obj["spatial_caption"] = []
                obj["spatial_caption"].append(caption)

    return objects

def find_jsons_in_video(video_path, json_name):
    """åœ¨å•ä¸ªè§†é¢‘ç›®å½•ä¸‹æŸ¥æ‰¾æ‰€æœ‰ JSON æ–‡ä»¶è·¯å¾„"""
    json_paths = []
    if not os.path.isdir(video_path):
        return json_paths
    try:
        for frame_folder in os.listdir(video_path):
            frame_path = os.path.join(video_path, frame_folder)
            json_path = os.path.join(frame_path, json_name)
            if os.path.isfile(json_path):
                json_paths.append(json_path)
    except Exception as e:
        print(f"âŒ Error reading {video_path}: {e}")
    return json_paths

def find_all_json_files_parallel(root_dir, json_name, num_workers=None):
    video_dirs = [
        os.path.join(root_dir, d)
        for d in os.listdir(root_dir)
        if os.path.isdir(os.path.join(root_dir, d))
    ]

    if num_workers is None:
        num_workers = max(1, cpu_count())

    print(f"ğŸ” Found {len(video_dirs)} video dirs, launching {num_workers} workers to search for JSON...")

    with Pool(processes=num_workers) as pool:
        func = partial(find_jsons_in_video, json_name=json_name)
        all_json_lists = list(tqdm(pool.imap_unordered(func, video_dirs), total=len(video_dirs), desc="Searching"))

    # Flatten the nested list
    json_paths = [path for sublist in all_json_lists for path in sublist]
    return json_paths

# ---------- å•ä¸ªæ–‡ä»¶çš„å¤„ç†å‡½æ•° ----------
def process_single_json(json_path, ratio_threshold):
    try:
        with open(json_path, "r") as f:
            data = json.load(f)

        if "objects" not in data or not isinstance(data["objects"], list):
            return

        # ä½¿ç”¨ä¼ å…¥çš„ ratio_threshold
        data["objects"] = process_objects(data["objects"], ratio_threshold=ratio_threshold)

        with open(json_path, "w") as f:
            json.dump(data, f, indent=2)

        return True
    except Exception as e:
        print(f"âŒ Error processing {json_path}: {e}")
        return False

def process_all_jsons_parallel(json_paths, ratio_threshold=0.7, num_workers=None):
    if num_workers is None:
        num_workers = max(1, cpu_count())

    print(f"ğŸš€ Launching pool with {num_workers} workers...")

    with Pool(processes=num_workers) as pool:
        # åˆ›å»ºéƒ¨åˆ†å‡½æ•°
        worker_fn = partial(process_single_json, ratio_threshold=ratio_threshold)
        list(tqdm(pool.imap_unordered(worker_fn, json_paths), total=len(json_paths), desc="Processing"))

    print("âœ… All JSON files processed.")

# ---------- ä¸»å…¥å£ ----------
if __name__ == "__main__":
    all_jsons = find_all_json_files_parallel(ROOT_DIR, JSON_FILENAME)
    print(f"ğŸ” Found {len(all_jsons)} JSON files.")
    process_all_jsons_parallel(all_jsons, RATIO_THRESHOLD)